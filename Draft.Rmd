---
title: "Predicting Ambient Air Pollution (PM2.5) Across the Contiguous U.S."
author: "Aileen Li, Nyah Strickland"
date: "2023-04-18"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Predicting Ambient Air Pollution (PM2.5) Across the Contiguous U.S.

  Air pollution has consequences for everyone, most especially for those with pre-existing conditions. To measure air pollution, we measure tiny particles or droplets in the air that are two and one-half microns or less in width called PM2.5. So being able to predict the average PM2.5 concentrations will allow us to keep people most susceptible safe as we look for and implement changes to improve the air quality in the region. We chose the predictors by ----. For our four models, we chose linear regression, k-nearest neighbors, bootstrapping, and random forest. Linear regression will model a linear relationship between the PM2.5 value in the atmosphere and the predictors. K-nearest neighbors will return predicted PM2.5 values based on their neighboring data points. Bootstrapping resamples the given data multiple times and returns predictions based on their average. Random forest makes an averaged prediction from a collection of independent decision trees. We predict that the RMSE performance of the bootstrapping model will be the best.

```{r}
library(tidyverse)
library(tidymodels)
library(broom)
library(carat)
library(randomForest)
library(plotROC)

origin <- read_csv("https://github.com/rdpeng/stat322E_public/raw/main/data/pm25_data.csv.gz")
```

## Wrangling
```{r Predictors}
# Split origin dataset into 80/20
dat_split <- initial_split(origin, prop =.8)
dat_split

# Use 80% of data for training 
train <- training(dat_split)

# Create standardize train data for kNN


# Visualize linear relationship between predictors (lat, lon, state) and predicted value


```

## Models 
```{r Linear Regression}
# Create the recipe for all models
rec <- origin %>% 
    recipe(value ~ lat + lon + state) 

# Linear regr. model
model1 <- linear_reg() %>% 
    set_engine("lm") %>% 
    set_mode("regression")

wf1 <- workflow() %>% 
    add_recipe(rec) %>% 
    add_model(model1)
# wf1

res1 <- fit(wf1, data = train)

# Check performance of linear regression model on the complete training data
res1 %>% 
    extract_fit_engine() %>% 
    summary()

# Check  linear regression model performance using cross-validation
folds1 <- vfold_cv(train, v = 10)
folds1
res1 <- fit_resamples(wf1, resamples = folds1)
res1 %>% 
    collect_metrics()
```
```{r kNN}
## Scale the data for k-NN model
origin_scaled <- origin %>% 
    mutate(across(-value, scale))

## Create kNN model
model2 <- nearest_neighbor(neighbors = 5) %>% 
    set_engine("kknn") %>% 
    set_mode("classification")

## Create workflow
  wf2 <- workflow() %>% 
    add_recipe(rec) %>% 
    add_model(model2)

## Fit the model on the full training dataset using the `fit()` function
pokemon_kNN <- fit(wf2, data = train)

## Check performance on the complete training data
res2 %>% 
    extract_fit_engine() %>% 
    summary()

## Check performance using cross-validation
folds <- vfold_cv(train, v = 10)
folds
res2 <- fit_resamples(wf2, resamples = folds)
res2 %>% 
    collect_metrics()
```

```{r Bootstrap}
## Create Bootstrap Model
model3 <- nearest_neighbor(neighbors = 5) %>% 
    set_engine("kknn") %>% 
    set_mode("classification")

## Create workflow
  wf3 <- workflow() %>% 
    add_recipe(rec) %>% 
    add_model(model3)
    
```

```{r Random Forests}
## Create Random Forest Model
model4 <- rand_forest(mtry = 5) %>% 
    set_engine("ranger") %>% 
    set_mode("regression")

## Create workflow
  wf4 <- workflow() %>% 
    add_recipe(rec) %>% 
    add_model(model4)

```





